---
Title: Predicting Student Grades'using Higher Education Student Performance and Evaluation  Dataset
Author: Fatimah & Nauman
Date: '2023-05-01'
Output: html_document
---


Data set link is [https://archive.ics.uci.edu/ml/datasets/Higher+Education+Students+Performance+Evaluation+Dataset] here.


# Data Set Information:

1-10 of the data are the personal questions, 11-16. questions include family 
questions, and the remaining questions include education habits.

The Higher Education Students Performance Evaluation Dataset is a dataset that 
contains information about the academic performance of higher education students.
The dataset usually includes various demographic, academic, and social factors 
that are believed to influence a student's academic performance. By analyzing 
this dataset, researchers can identify patterns and trends in students'
performance and better understand the factors that contribute to their success 
or failure in higher education.


## Attribute Information:

   Student ID
1- Student Age (1: 18-21, 2: 22-25, 3: above 26)

2- Sex (1: female, 2: male)

3- Graduated high-school type: (1: private, 2: state, 3: other)

4- Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)

5- Additional work: (1: Yes, 2: No)

6- Regular artistic or sports activity: (1: Yes, 2: No)

7- Do you have a partner: (1: Yes, 2: No)

8- Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)

9- Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)

10- Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)

11- Mothersâ€™ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 
5: MSc., 6: Ph.D.)

12- Fathersâ€™ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)

13- Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)

14- Parental status: (1: married, 2: divorced, 3: died - one of them or both)

15- Mothersâ€™ occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)

16- Fathersâ€™ occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)

17- Weekly study hours: (1: None, 2: <5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)

18- Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)

19- Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)

20- Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)

21- Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)

22- Attendance to classes (1: always, 2: sometimes, 3: never)

23- Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)

24- Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)

25- Taking notes in classes: (1: never, 2: sometimes, 3: always)

26- Listening in classes: (1: never, 2: sometimes, 3: always)

27- Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)

28- Flip-classroom: (1: not useful, 2: useful, 3: not applicable)

29- Cumulative grade point average in the last semester (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 
2.50-2.99, 4: 3.00-3.49, 5: above 3.49)

30- Expected Cumulative grade point average in the graduation (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)

31- Course ID

32- OUTPUT Variable: Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)

```{r}
library(dplyr)
setwd("E:/Master's Business Analytics/semester 3/Predictive Modeling/Final Project/Data")
data1 <- read.csv("E:/Master's Business Analytics/semester 3/Predictive Modeling/Final Project/Data/my_data.csv")
```
Checking if levels are defined in the dataset since the data is categorical
```{r}
levels(data1)


```
```{r}
library(dplyr)
colSums(is.na(data1)) %>% 
  sort()
```
### No NULL Values
 
 Since there are no Levels defined, We will now define levels first.

#Adding a new column GRADE1 (This will have 4 categories: Fail, Below Average, Average, Above Average, Distinction )
```{r}
data1$GRADE1 <- with(data1, ifelse(GRADE == 0, "Fail", 
                               ifelse(GRADE <= 3, "Below Average", ifelse( GRADE < 6,
                                                                           "Average", 
                                      ifelse(GRADE < 7, "Above   Average","Distinction")))))
```
Now we will e Transforming coded data into characters
```{r}
#Student_Age
data1$Student_Age <- ifelse(data1$Student_Age == 1, "18-21", 
                                         ifelse(data1$Student_Age == 2, "22-25", 
                                                ifelse(data1$Student_Age == 3, "above 26", NA)))

```
```{r}
#Sex
data1$Sex <- ifelse(data1$Sex == 1, "female", 
                      ifelse(data1$Sex == 2, "male", NA))

#Graduate_high_school
data1$Graduated_high_school <- ifelse(data1$Graduated_high_school == 1, "private", 
                                        ifelse(data1$Graduated_high_school == 2, "state", "other"))


# Scholarship type
data1$Scholarship_type <- ifelse(data1$Scholarship_type == 1, "None",
                              ifelse(data1$Scholarship_type == 2, "25%",
                                     ifelse(data1$Scholarship_type == 3, "50%",
                                            ifelse(data1$Scholarship_type == 4, "75%", "Full"))))

# Additional work
data1$Additional_work <- ifelse(data1$Additional_work == 1, "Yes", "No")

# Regular artistic or sports activity
data1$Regular_artistic_sports_activity <- ifelse(data1$Regular_artistic_sports_activity == 1, "Yes", "No")

# Do you have a partner
data1$partner_Status <- ifelse(data1$partner_Status == 1, "Yes", "No")

# Total salary if available
data1$Total_salary <- ifelse(data1$Total_salary == 1, "USD 135-200",
                          ifelse(data1$Total_salary == 2, "USD 201-270",
                                 ifelse(data1$Total_salary == 3, "USD 271-340",
                                        ifelse(data1$Total_salary == 4, "USD 341-410", "above 410"))))

# Transportation to the university
data1$Transport <- ifelse(data1$Transport == 1, "Bus",
                            ifelse(data1$Transport == 2, "Private car/taxi",
                                   ifelse(data1$Transport == 3, "bicycle", "Other")))

# Accommodation type in Cyprus
data1$Accommo. <- ifelse(data1$Accommo. == 1, "rental",
                           ifelse(data1$Accommo. == 2, "dormitory",
                                  ifelse(data1$Accommo. == 3, "with family", "Other")))

# Mothers' education
data1$Mothers_edu <- ifelse(data1$Mothers_edu == 1, "primary school",
                               ifelse(data1$Mothers_edu == 2, "secondary school",
                                      ifelse(data1$Mothers_edu == 3, "high school",
                                             ifelse(data1$Mothers_edu == 4, "university",
                                                    ifelse(data1$Mothers_edu == 5, "MSc.", "Ph.D.")))))

# Fathers' education
data1$Fathers_edu <- ifelse(data1$Fathers_edu == 1, "primary school",
                               ifelse(data1$Fathers_edu == 2, "secondary school",
                                      ifelse(data1$Fathers_edu == 3, "high school",
                                             ifelse(data1$Fathers_edu == 4, "university",
                                                    ifelse(data1$Fathers_edu == 5, "MSc.", "Ph.D.")))))

# Number of sisters/brothers
data1$Num_Siblings <- ifelse(data1$Num_Siblings == 1, "1",
                      ifelse(data1$Num_Siblings == 2, "2",
                             ifelse(data1$Num_Siblings == 3, "3",
                                    ifelse(data1$Num_Siblings == 4, "4", "5 or above"))))

# Parental status
data1$Parental_status <- ifelse(data1$Parental_status == 1, "married",
                             ifelse(data1$Parental_status == 2, "divorced", "died - one of them or both"))

# Mothers occupation
data1$Mothers_occupation <- ifelse(data1$Mothers_occupation == 1, "retired",
                           ifelse(data1$Mothers_occupation == 2, "housewife",
                                  ifelse(data1$Mothers_occupation == 3, "government officer",
                                         ifelse(data1$Mothers_occupation == 4, "private sector employee",
                                                ifelse(data1$Mothers_occupation == 5, "self-employment",
                                                       ifelse(data1$Mothers_occupation == 6, "other", NA))))))

#Father's Occupation
data1$Fathers_occupation <- ifelse(data1$Fathers_occupation == 1, "retired",
                           ifelse(data1$Fathers_occupation == 2, "government officer",
                                  ifelse(data1$Fathers_occupation == 3, "private sector employee",
                                         ifelse(data1$Fathers_occupation == 4,
                                                "self-employment",
                                                ifelse(data1$Fathers_occupation == 5, "other", NA)))))

# Weekly Study Hours
data1$Weekly_study <- ifelse(data1$Weekly_study == 1, "None",
                           ifelse(data1$Weekly_study == 2, "<5 hours",
                                  ifelse(data1$Weekly_study == 3, "6-10 hours",
                                         ifelse(data1$Weekly_study == 4, "11-20 hours",
                                                ifelse(data1$Weekly_study == 5, "more than 20 hours", NA)))))

# Non Scientific Reading Frequency
data1$Reading_freq_nonScientifc <- ifelse(data1$Reading_freq_nonScientifc == 1, "None",
                                     ifelse(data1$Reading_freq_nonScientifc == 2, "Sometimes",
                                            ifelse(data1$Reading_freq_nonScientifc == 3, "Often", NA)))

# Reading frequency Scientific 
data1$Reading_freq_Scientifc <- ifelse(data1$Reading_freq_Scientifc == 1, "None",
                                     ifelse(data1$Reading_freq_Scientifc == 2, "Sometimes",
                                            ifelse(data1$Reading_freq_Scientifc == 3, "Often", NA)))

# Seminar Attendance 
data1$Attendance_seminar <- ifelse(data1$Attendance_seminar == 1, "Yes",
                                        ifelse(data1$Attendance_seminar == 2, "No", NA))
#Impact of your projects/activities on your success
data1$Impact_proj <- ifelse(data1$Impact_proj == 1, "positive",
                          ifelse(data1$Impact_proj == 2, "negative",
                                 ifelse(data1$Impact_proj == 3, "neutral", NA)))
#Attendance to classes
data1$Attendance_class <- ifelse(data1$Attendance_class == 1, "always",
                              ifelse(data1$Attendance_class == 2, "sometimes",
                                     ifelse(data1$Attendance_class == 3, "never", NA)))

#Preparation to midterm exams1
data1$Prep_mid1 <- ifelse(data1$Prep_mid1 == 1, "alone",
                                  ifelse(data1$Prep_mid1 == 2,
                                         "with friends", "not applicable"))


#Preparation to midterm exams 2
data1$Prep_mid2 <- ifelse(data1$Prep_mid2 == 1, "closest date to the exam",
                                  ifelse(data1$Prep_mid1 == 2,
                                         "regularly during the semester", "not applicable"))

# Taking notes in classes
data1$Taking_notes <- ifelse(data1$Taking_notes == 1, "never",
                             ifelse(data1$Taking_notes == 2, "sometimes", "always"))
# Listening in classes
data1$Listening <- ifelse(data1$Listening == 1, "never",
                             ifelse(data1$Listening == 2, "sometimes", "always"))
# Discussion improves my interest and success in the course
data1$Discussion <- ifelse(data1$Discussion == 1, "never",
                             ifelse(data1$Discussion == 2, "sometimes", "always"))
# Flip-classroom
data1$Flip_classroom <- ifelse(data1$Flip_classroom == 1, "not useful",
                             ifelse(data1$Flip_classroom == 2, "useful", "not applicable"))

# Cumulative grade point average in the last semester
data1$CGPA <- ifelse(data1$CGPA == 1, "<2.00",
                          ifelse(data1$CGPA == 2, "2.00-2.49",
                          ifelse(data1$CGPA == 3, "2.50-2.99",
                          ifelse(data1$CGPA == 4, "3.00-3.49",
                                 "above 3.49"))))

data1$ExCGPA <- ifelse(data1$ExCGPA == 1, "<2.00",
                                ifelse(data1$ExCGPA == 2, "2.00-2.49",
                                ifelse(data1$ExCGPA == 3, "2.50-2.99",
                                ifelse(data1$ExCGPA == 4, "3.00-3.49",
                                       "above 3.49"))))

```

### Using Dplyr, remove columns from dataset. This will remove columns (variables) that are not helping us in predicting GRADE1
- Grade
- Course.ID
- Student.ID

```{r}
library(dplyr)
dataset <- data1 %>% 
   select( -GRADE, -COURSE.ID, - STUDENT.ID)

```
### Now we will define levels. This is done with the purpose to convert categorical data into factors 
```{r}
dataset <- lapply(dataset, as.factor)
levels(dataset$Student_Age)
dataset <- data.frame(dataset)
levels(dataset$Student_Age)
table(dataset$Student_Age)
```
### Lets divide the data into a learning and testing sample.
### It can be done for example with the use of
### of the createDataPartition() function from the caret package

### Because the split is random to be identical for
### everyone we will use the defined random seed
### The use of set. seed is to make sure that we get the same results for randomization
```{r}
library(caret)
library(dplyr)
library(tibble)
library(purrr)
library(corrplot)
library(DescTools)

glimpse(dataset)
head(dataset)

set.seed(987654321)
dataset_which_train <- createDataPartition(dataset$GRADE1, # target variable
                                               # share of the training sample
                                               p = 0.7,
                                               # should result be a list?
                                               list = FALSE)
dataset_train <- dataset[dataset_which_train,]
dataset_test <- dataset[-dataset_which_train,]
glimpse(dataset_train)
glimpse(dataset_test)

summary(dataset_test)
summary(dataset_train)
```




# Exploratory Data Analysis
Performing EDA on categorical data involves examining the distribution of categories, identifying patterns and trends, and exploring the relationship between different categorical variables. This can help provide insights into the underlying patterns and structure of the data.

```{r}
library(ggplot2)


ggplot(dataset_train, 
       aes(x = Sex, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Student_Age, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Scholarship_type, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Regular_artistic_sports_activity, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Transport, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Accommo., 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Mothers_edu, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Fathers_edu, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Weekly_study, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Attendance_class, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Prep_mid2, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Taking_notes, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Listening, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Accommo., 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = Discussion, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

ggplot(dataset_train, 
       aes(x = ExCGPA, 
           fill = GRADE1)) + 
  geom_bar(position = "stack")

#summary of data

summary(dataset_train)
summary(dataset_train)
glimpse(dataset_train)

#Pie chart

pie_chart_Student_age <- ggplot(dataset_train, aes(x="", fill= Student_Age)) +
  geom_bar(stat="count", width=1) +
  coord_polar("y", start=0) +
  labs(title="Student Age Distribution", fill="Student Age") +
  theme_void()

print(pie_chart_Student_age)



```
The above pie chart shows the distribution of student age in the data. The majority of students lie in the age bracket of age 22-25 , followed by 18 - 21. Students in the category above 26 are lowest.
```{r}
pie_chart_Sex <- ggplot(dataset_train, aes(x="", fill= Sex)) +
  geom_bar(stat="count", width=1) +
  coord_polar("y", start=0) +
  labs(title="Student Sex Distribution", fill="Sex") +
  theme_void()

print(pie_chart_Sex)
```
Student sex distribution pie chart shows male students > female students present in the data.

```{r}
pie_chart_Transport <- ggplot(dataset_train, aes(x="", fill= Transport)) +
  geom_bar(stat="count", width=1) +
  coord_polar("y", start=0) +
  labs(title="Transport Distribution", fill="Transport") +
  theme_void()

print(pie_chart_Transport)

```
The pie chart titled ' Transport distribution' tells us that the widely used
transport medium is 'Bus' followed by 'private car/taxi' and then 'Other'


# perform feature selection using the chi-squared test on every variable
```{r include=FALSE}

library(caret)
library(MASS)
glimpse(dataset_train)

sum(is.na(dataset_train))
table(dataset_train$GRADE1, dataset_train$Accommo.) #with table its working
chisq.test(dataset_train$GRADE1, dataset_train$Accommo., correct = FALSE)

chisq.test(dataset_train$Student_Age, dataset_train$GRADE1) #significant

chisq.test(dataset_train$Sex, dataset_train$GRADE1) #significant

chisq.test(dataset_train$Graduated_high_school, dataset_train$GRADE1)

chisq.test(dataset_train$Scholarship_type, dataset_train$GRADE1) #might be

chisq.test(dataset_train$Additional_work, dataset_train$GRADE1)

chisq.test(dataset_train$Graduated_high_school, dataset_train$GRADE1)

chisq.test(dataset_train$Regular_artistic_sports_activity, dataset_train$GRADE1)

chisq.test(dataset_train$partner_Status, dataset_train$GRADE1)

chisq.test(dataset_train$Total_salary, dataset_train$GRADE1)

chisq.test(dataset_train$Transport, dataset_train$GRADE1) #significant

chisq.test(dataset_train$Mothers_edu, dataset_train$GRADE1)

chisq.test(dataset_train$Fathers_edu, dataset_train$GRADE1)

chisq.test(dataset_train$Num_Siblings, dataset_train$GRADE1)

chisq.test(dataset_train$Parental_status, dataset_train$GRADE1)

chisq.test(dataset_train$Mothers_occupation, dataset_train$GRADE1) #significant

chisq.test(dataset_train$Fathers_occupation, dataset_train$GRADE1)

chisq.test(dataset_train$Weekly_study, dataset_train$GRADE1)

chisq.test(dataset_train$Reading_freq_nonScientifc, dataset_train$GRADE1) #significant

chisq.test(dataset_train$Reading_freq_Scientifc, dataset_train$GRADE1)

chisq.test(dataset_train$Attendance_seminar, dataset_train$GRADE1)

chisq.test(dataset_train$Prep_mid1, dataset_train$GRADE1)

chisq.test(dataset_train$Prep_mid2, dataset_train$GRADE1)

chisq.test(dataset_train$Taking_notes, dataset_train$GRADE1)

chisq.test(dataset_train$Listening, dataset_train$GRADE1)

chisq.test(dataset_train$Discussion, dataset_train$GRADE1)

chisq.test(dataset_train$Flip_classroom, dataset_train$GRADE1)

chisq.test(dataset_train$CGPA, dataset_train$GRADE1)

chisq.test(dataset_train$ExCGPA, dataset_train$GRADE1)

#After the chi test, the variables we will select for predicting GRADE1 are:

#1. Student_Age
#2. Sex
#3. Transport
#4. Mothers_occupation
#5. Scholarship_type
#6. Reading_freq_nonScientific

```

```{r include=FALSE}
# checking for Multicollinearity

# Define a function to perform chi-square test on two categorical variables
chisq_func <- function(x, y) {
  chisq <- chisq.test(x, y)
  return(list(chisq_statistic = chisq$statistic, p_value = chisq$p.value))
}

# Use lapply to apply chisq_func to all pairs of categorical variables
cat_vars <- sapply(dataset_train, function(x) is.factor(x) | is.character(x))
chisq_results <- lapply(names(dataset_train)[cat_vars], function(var1) {
  lapply(names(dataset_train)[cat_vars], function(var2) {
    if (var1 != var2) {
      result <- chisq_func(dataset_train[[var1]], dataset_train[[var2]])
      return(list(var1 = var1, var2 = var2, chisq_statistic = result$chisq_statistic, p_value = result$p_value))
    } else {
      return(NULL)
    }
  })
})

# Combine the results into a data frame
chisq_results <- do.call(rbind, lapply(chisq_results, function(x) do.call(rbind, x)))

# Print the results
# print(chisq_results)
data.frame(chisq_results)
# View(chisq_results)
      
```

```{r}
library(knitr)
knitr::kable(chisq_results)

```

# Now we will run Multinomial Logistic Regression to predict GRADE1 of students using all Features of the Training Dataset.
```{r}
library(caret)
library(nnet)
library(dplyr)

library(lmtest)
Grades_multi <- multinom(GRADE1 ~ .,data = dataset_train, maxit = 800)


predict(Grades_multi)

Grades_mlogit1_fitted <- predict(Grades_multi)
table(Grades_mlogit1_fitted)


predict(Grades_multi,
        type = "probs") %>%
  head()
```

```{r}

# Create a confusion matrix
cm <- confusionMatrix(Grades_mlogit1_fitted, dataset_train$GRADE1)

# Print the confusion matrix
cm$table

# Calculate the accuracy
accuracy <- sum(diag(cm$table))/sum(cm$table)
print("The accuracy of the model is:")
accuracy

# Calculate the error
error <- 1 - accuracy
print("The error of the model is:")
error
```
Based on the above confusion Matrix, the model has accurately predicted real values.The given confusion matrix is a result of logistic regression on a categorical variable GRADE1 against other categorical variables. The matrix represents the predicted vs actual values for each level of the GRADE1 variable.

The rows represent the actual values of GRADE1, while the columns represent the predicted values.

The values in the diagonal represent the number of correct predictions for each level of GRADE1. For example, for the level Above Average, 10 observations were predicted correctly as Above Average. 
19 observations were predicted correctly as Average
56 observations were predicted correctly as Below Average
12 Observations were predicted as Distinction
6 Observations were predicted as Fail


# Applying the trained model to the test dataset. To validate the model accuracy. 
## Followed by checking the accuracy and error.
```{r}
# Load the required libraries
library(caret)
library(nnet)

# Train the multinomial logistic regression model on the training data

# Make predictions on the test data
Grades_mlogit1_pred <- predict(Grades_multi, newdata = dataset_test)

# Create a confusion matrix
cm <- confusionMatrix(Grades_mlogit1_pred, dataset_test$GRADE1)

# Print the confusion matrix
cm$table

# Calculate the accuracy
accuracy <- sum(diag(cm$table))/sum(cm$table)
print("The accuracy of the model is:")
accuracy

# Calculate the error
error <- 1 - accuracy
print("The error of the model is:")
error

```
The above model evaluation is carried on training dataset. 

### Clearly there is an overfitting issue in the model. Since the model run well on the training data. However, the model did not perform well on the testing data. 

### The accuracy of the model is 0.380 (38%)
### The error of the model is 0.6190 (61.9%)
The values in the diagonal represent the number of correct predictions for each level of GRADE1. For example, for the level Above Average, 1 observations were predicted correctly as Above Average. 
2 observations were predicted correctly as Average out of 11
12 observations were predicted correctly as Below Average out of 19
1 Observations were predicted as Distinction out of 5
1 Observations were predicted as Fail out of 6



#Now we will run Logistic Regression on selected variables from Chi Square test.
```{r}
#The variables we will select for predicting GRADE1 are based on chi-square test performed previously: (SF stands for selected features)

#1. Student_Age
#2. Sex
#3. Transport
#4. Mothers_occupation
#5. Scholarship_type
#6. Reading_freq_nonScientific
```

Training model on train dataset
```{r}
Grades_multi_SF <- multinom(GRADE1 ~ Student_Age + Sex + Transport + Mothers_occupation + Scholarship_type + Reading_freq_nonScientifc ,data = dataset_train, maxit = 800)

# summary(Grades_multi_SF)

predict(Grades_multi_SF)

Grades_mlogitSF_fitted <- predict(Grades_multi_SF)
table(Grades_mlogitSF_fitted)


predict(Grades_multi_SF,
        type = "probs") %>%
  head()

table(Grades_mlogitSF_fitted, # fitted in rows
      dataset_train$GRADE1) # real in columns

#After feature selection, logistic regression model is not predicting accurately so we will use all features for GRADE1 Prediction.
```
After feature selection, logistic regression model is not predicting accurately so we will use all features for GRADE1 Prediction.
```{r}
# Create a confusion matrix
cm <- confusionMatrix(Grades_mlogitSF_fitted, dataset_train$GRADE1)

# Print the confusion matrix
cm$table

# Calculate the accuracy
accuracy <- sum(diag(cm$table))/sum(cm$table)
print("The accuracy of the model is:")
accuracy

# Calculate the error
error <- 1 - accuracy
print("The error of the model is:")
error
```
## By including only the slected features into the logit model, the accuracy turned out to be 0.699 (69.9%). While the error rate of the model is 0.300 (30.1%)

```{r}
#1. Student_Age
#2. Sex
#3. Transport
#4. Mothers_occupation
#5. Scholarship_type
#6. Reading_freq_nonScientific
# Create a data frame with selected columns from the test data
dataset_test_SF <- data.frame(
  Student_Age = dataset_test$Student_Age,
  Sex = dataset_test$Sex,
  Transport = dataset_test$Transport,
  Mothers_occupation = dataset_test$Mothers_occupation,
  Scholarship_type = dataset_test$Scholarship_type,
  Reading_freq_nonScientifc = dataset_test$Reading_freq_nonScientifc,
  GRADE1 = dataset_test$GRADE1
)

# Convert categorical variables to factors
dataset_test_SF$Sex <- as.factor(dataset_test_SF$Sex)
dataset_test_SF$Transport <- as.factor(dataset_test_SF$Transport)
dataset_test_SF$Mothers_occupation <- as.factor(dataset_test_SF$Mothers_occupation)
dataset_test_SF$Scholarship_type <- as.factor(dataset_test_SF$Scholarship_type)
dataset_test_SF$Reading_freq_nonScientifc <- as.factor(dataset_test_SF$Reading_freq_nonScientifc)
dataset_test_SF$GRADE1 <- as.factor(dataset_test_SF$GRADE1)
dataset_test_SF

# Make predictions using the trained model
Grades_mlogitSF_predict <- predict(Grades_multi_SF, newdata = dataset_test_SF)

# Create a confusion matrix
cm <- confusionMatrix(Grades_mlogitSF_predict, dataset_test_SF$GRADE1)

# Print the confusion matrix
cm$table


# Calculate the accuracy
accuracy <- sum(diag(cm$table))/sum(cm$table)

accuracy

# Calculate the error
error <- 1 - accuracy

error

```

With selected features the acuracy of the model on test dataset is 50% 
when compared to the model accuracy of training dataset. The accuracy and the error was 69% and 31%.
So, again there is an overfitting issue in the model.

# Decision Tree

```{r}
hist(as.numeric(dataset_train$GRADE1))

```
```{r}
library(tree)
# Build decision tree model using training data
tree.Grade <- tree(GRADE1 ~ Student_Age + Sex + Transport + Mothers_occupation + Scholarship_type + Reading_freq_nonScientifc,
                   data = dataset_train)

# Print summary of the model
summary(tree.Grade)

```

```{r}
plot(tree.Grade)
text(tree.Grade, splits = TRUE, pretty = 0)
```
#Now Running Decision Tree on Test dataset
```{r}
tree.pred2 = predict(tree.Grade, dataset_test_SF, type="class")
cm2 <-with(dataset_test_SF, table(tree.pred2, GRADE1))
cm2
accuracy <- sum(diag(cm2))/sum(cm2)

accuracy

# Calculate the error
error <- 1 - accuracy
error
```
### Again Our Decision Tree Model is showing overfitting. where the misclassification error rate of traning dataset was 0.368 but on the test dataset it is 0.57.



# let's use cross-validation to prune the tree optimally.
## Using cv.tree, we will use the misclassification error as the basis for doing the pruning.

```{r}
# Cross Validating on Decision Tree
cv.grades= cv.tree(tree.Grade, FUN = prune.misclass)
cv.grades

# Plotting the resut of pruning
plot(cv.grades)
```
```{r}
# Selecting the best classes to predict the outcome Variable
prune.grades = prune.misclass(tree.Grade, best = 4)

# Plotting the Decision tree
plot(prune.grades)
text(prune.grades, pretty=0)
```
# USing the CV model to predict the test dataset
```{r}
# Validatign the CV model on test dataset
tree.pred = predict(prune.grades, dataset_test_SF, type="class")

# Creating a confusion matrix
cm3 <- with(dataset_test_SF, table(tree.pred, GRADE1))

# Confusion Matrix
cm3

# Checking the accuracy
accuracy <- sum(diag(cm3))/sum(cm3)
accuracy

# Calculate the error
error <- 1 - accuracy
error
```
[1] 0.4285714
[1] 0.5714286


### With Cross Validation, the error rate of our model has reduced from 57% to 40%. which is a significant decrease. While the accuracy of model prediction has also increased from 42.8% to 59.5%.


# Random Forest

```{r}
# Loading the randomForest Package
require('randomForest')

# Running the model on traning dataset
rf.Grades = randomForest(GRADE1~., data = dataset_train)
rf.Grades

```
### Error rate of RandomForest = 42.72%
### Accuracy of RandomForest = 57.28%

```{r}
# Validating the model on test dataset.
rf.pred = predict(rf.Grades, dataset_test, type="class")
cm3 <-with(dataset_test, table(rf.pred, GRADE1))
cm3
accuracy <- sum(diag(cm3))/sum(cm3)

accuracy

# Calculate the error
error <- 1 - accuracy
error
```
## Training Data
### Error rate of RandomForest = 42.72%
### Accuracy of RandomForest = 57.28%

## Test Dataset
### The Error rate on test dataset = 45.2%
### The Accuracy on test dataset = 54.74%
 Here again we have encountered Overfitting issue in the model. 


# Among all the models, Cross Validation with Decision Tree performed relaively well with alomst 60% accuracy on the test dataset. 
